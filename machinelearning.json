{
	"title": {
		"media": {
			"url": "https://iticollege.edu/wp-content/uploads/2024/07/Machine-Learning-Basics.jpg"
			
		},
		"text": {
			"headline": "Digital Timeline - History of Machine Learning <br/> 31S1",
			"text": "<p>Machine learning's legacy dates from the early beginnings of neural networks to recent advancements in generative AI that democratize new and controversial ways to create content.</p>"
		}
	},
	"events": [
		{
			"media": {
				"url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh9wO17oF6ndZVYRhXR9MgRm0Rlvvcuws6Jhdmn_m1eOOQXX1DHAb0zHD8nF2wa2NVa_vs5IwiYNLgMcHTmY1vo0bcpQUepOYbwURgq-LI5ZoNoOcPDcTGz65cylAJW3_z9-colRw/s282/Mccullochpitts.jpeg"
			},
			"start_date": { "year": "1943"},
			"text": 
			{
				"headline": "First Mathematical Model of Neural Networks",
				"text": "<p>In 1943, Warren McCulloch and Walter Pitts published *“A Logical Calculus of the Ideas Imminent in Nervous Activity,”* introducing the first mathematical model of a neural network. Their work, inspired by Alan Turing, showed how simple connected elements could perform powerful computations, later influencing John von Neumann, Norbert Wiener, and others.</p>"
			}
		},
		{
			"media": {
				"url": "https://youtu.be/dDTf7QYUq48"
			},
			"start_date": { "year": "1949" },
			"text": {
				"headline": "Hebb’s Learning Theory",
				"text": "<p>Donald Hebb published <i>The Organization of Behavior</i>, a groundbreaking book on brain activity and neural networks. His theory explained how behavior and thought can be linked to changes in neural pathways.</p>"
			}
		},
		{
			"media": {
				"url": "https://www.investopedia.com/thmb/gHwmBhHZJkOcwJiIFAK0gBOIxqU=/750x0/filters:no_upscale():max_bytes(150000):strip_icc():format(webp)/turing-test.asp-FINAL-2-8e8b31263317454c828c2ca8ec518bbd.png",
				"caption": "The Turing Test",
				"credit": "Investopedia"
			},
			"start_date": { "year": "1950" },
			"text": {
				"headline": "The Turing Test",
				"text": "<p>Alan Turing introduced the Turing Test in his paper <i>Computing Machinery and Intelligence</i>. This test proposed a way to measure whether a machine could exhibit intelligent behavior indistinguishable from humans.</p>"
			}
		},
		{
			"media": {
				"url": "https://opendatascience.com/wp-content/uploads/2018/04/History-of-NN-1-CW-298x300.png"
			},
			"start_date": { "year": "1951" },
			"text": {
				"headline": "SNARC: First Artificial Neural Network",
				"text": "<p>In 1951, Marvin Minsky and Dean Edmonds built the Stochastic Neural Analog Reinforcement Calculator (SNARC), the first artificial neural network machine. Using 40 analog neurons with capacitors and potentiometers, it learned to solve a virtual maze, pioneering the concept of machine learning through reinforcement.</p>"
			}
		},
		{
			"media": {
				"url": "https://blogs-images.forbes.com/gilpress/files/2016/08/ai50160.jpg",
				"caption": "Five of the attendees of the 1956 Dartmouth Summer Research Project on Artificial Intelligence reunited at the July 2006 AI@50 conference. From left: Trenchard More, John McCarthy, Marvin Minsky, Oliver Selfridge, and Ray Solomonoff. (Photo by Joseph Mehling)",	
				"credit": "Forbes"
			},
			"start_date": { "year": "1956" },
			"text": {
				"headline": "Birth of Artificial Intelligence",
				"text": "<p>On August 31, 1955, John McCarthy, Marvin Minsky, Nathaniel Rochester, and Claude Shannon coined the term “artificial intelligence” in a research proposal for the Dartmouth workshop. Held in 1956, this event marked the official birth of AI, aiming to make machines use language, form concepts, solve human-like problems, and improve themselves.</p>"
			}
		},
		{
			"media": {
				"url": "https://i.insider.com/5a14a5033dbef4a7748b72ed?width=800&format=jpeg&auto=webp"
			},
			"start_date": { "year": "1959" },
			"text": {
				"headline": "Term 'Machine Learning' Coined",
				"text": "<p>Arthur Samuel coined the term <i>machine learning</i> when he showed that a computer could be programmed to outperform its programmer. Around the same time, Oliver Selfridge’s <i>“Pandemonium”</i> introduced a model that adaptively improved itself to recognize patterns in data.</p>"
			}
		},
		{
			"media": {
				"url": "https://youtu.be/zhxNI7V2IxM"
			},
			"start_date": { "year": "1966" },
			"text": {
				"headline": "Eliza & Shakey the Robot",
				"text": "<p>In 1966, Joseph Weizenbaum created <i>Eliza</i>, a program that simulated human-like conversations. That same year, the Stanford Research Institute developed <i>Shakey</i>, the first mobile intelligent robot, laying the groundwork for self-driving cars and drones.</p>"
			}
		},
		{
			"media": {
				"url": "https://miro.medium.com/v2/resize:fit:1100/format:webp/0*QBN0np_l26i_URnH"
			},
			"start_date": { "year": "1969" },
			"text": {
				"headline": "Backpropagation & Perceptrons",
				"text": "<p>In 1969, Arthur Bryson and Yu-Chi Ho introduced a <b>backpropagation algorithm</b> for multilayer neural networks, laying the foundation for deep learning. That same year, Marvin Minsky and Seymour Papert’s book <i>Perceptrons</i> highlighted the limits of simple networks, leading to a decline in neural network research and a rise in symbolic AI.</p>"
			}
		},
		{
			"media": {
				"url": "https://askpromotheus.ai/wp-content/uploads/2025/04/HINTON-01web-video.jpg"
			},
			"start_date": { "year": "2006" },
			"text": {
				"headline": "Deep Learning",
				"text": "<p>In 2006, Geoffrey Hinton coined the term <b>deep learning</b> to describe algorithms that enable computers to recognize objects and text in images and videos. This marked a major breakthrough in advancing modern AI capabilities.</p>"
			}
		},
		{
			"media": {
				"url": "https://www.harvardmagazine.com/sites/default/files/img/article/0919/hm_post_9.18.2019.jpg"
			},
			"start_date": { "year": "1989" },
			"text": {
				"headline": "Convolutional Neural Networks (CNNs)",
				"text": "<p>In 1989, Yann LeCun, Yoshua Bengio, and Patrick Haffner demonstrated convolutional neural networks (CNNs) for recognizing handwritten characters. This proved that neural networks could successfully tackle real-world applications.</p>"
			}
		},
		{
			"media": {
				"url": "https://d3f1iyfxxz8i1e.cloudfront.net/courses/course_image/876ec5406900.jpg"
			},
			"start_date": { "year": "2013" },
			"text": {
				"headline": "Deep Reinforcement Learning & word2vec",
				"text": "<p>In 2013, DeepMind introduced deep reinforcement learning, enabling a CNN to learn through rewards and surpass human experts in games. That same year, Tomas Mikolov and colleagues at Google developed word2vec, which automatically captured semantic relationships between words.</p>"
			}
		},
		{
			"media": {
				"url": "https://www.journal-publishing.com/wp-content/uploads/2019/09/References_Colorful_Texture_Blocks-950x640.jpg"
			},
			"start_date": { "year": "2025" },
			"text": 
			{
				"headline": "REFERENCES",
				"text": "<p>Karjian, R. (2024, June 13). History and evolution of machine learning: A timeline. TechTarget. Retrieved from <a href='https://www.techtarget.com/whatis/feature/History-and-evolution-of-machine-learning-A-timeline'>https://www.techtarget.com/whatis/feature/History-and-evolution-of-machine-learning-A-timeline</a><br><br>Norman, J. M. (n.d.). Marvin Minsky’s SNARC, possibly the first artificial self-learning machine [Web log post]. History of Information. Retrieved from <a href='https://www.historyofinformation.com/detail.php?entryid=782'>https://www.historyofinformation.com/detail.php?entryid=782</a><br><br>History of AI project. (n.d.). SNARC. Retrieved from <a href='https://historyof.ai/snarc/'>https://historyof.ai/snarc/</a><br><br>Press, G. (2016, August 28). Artificial intelligence defined as a new research discipline – This week in tech history. Forbes. Retrieved from <a href='https://www.forbes.com/sites/gilpress/2016/08/28/artificial-intelligence-defined-as-a-new-research-discipline-this-week-in-tech-history/'>https://www.forbes.com/sites/gilpress/2016/08/28/artificial-intelligence-defined-as-a-new-research-discipline-this-week-in-tech-history/</a></p>"
			}
		}
	]
}
